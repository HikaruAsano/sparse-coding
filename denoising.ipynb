{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan -0.00408252 ... -0.00783084         nan\n",
      "           nan]\n",
      "  ...\n",
      "  [        nan         nan -0.0066643  ... -0.00567531 -0.00408252\n",
      "           nan]\n",
      "  [        nan         nan         nan ... -0.00408252         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]]\n",
      "\n",
      " [[        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan -0.00408252 ... -0.00783084         nan\n",
      "           nan]\n",
      "  ...\n",
      "  [        nan         nan -0.0066643  ... -0.00567531 -0.00408252\n",
      "           nan]\n",
      "  [        nan         nan         nan ... -0.00408252         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]]\n",
      "\n",
      " [[        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan -0.00408252 ... -0.00783084         nan\n",
      "           nan]\n",
      "  ...\n",
      "  [        nan         nan -0.0066643  ... -0.00567531 -0.00408252\n",
      "           nan]\n",
      "  [        nan         nan         nan ... -0.00408252         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan -0.00408252 ... -0.00783084         nan\n",
      "           nan]\n",
      "  ...\n",
      "  [        nan         nan -0.0066643  ... -0.00567531 -0.00408252\n",
      "           nan]\n",
      "  [        nan         nan         nan ... -0.00408252         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]]\n",
      "\n",
      " [[        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan -0.00408252 ... -0.00783084         nan\n",
      "           nan]\n",
      "  ...\n",
      "  [        nan         nan -0.0066643  ... -0.00567531 -0.00408252\n",
      "           nan]\n",
      "  [        nan         nan         nan ... -0.00408252         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]]\n",
      "\n",
      " [[        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]\n",
      "  [        nan         nan -0.00408252 ... -0.00783084         nan\n",
      "           nan]\n",
      "  ...\n",
      "  [        nan         nan -0.0066643  ... -0.00567531 -0.00408252\n",
      "           nan]\n",
      "  [        nan         nan         nan ... -0.00408252         nan\n",
      "           nan]\n",
      "  [        nan         nan         nan ...         nan         nan\n",
      "           nan]]]\n"
     ]
    }
   ],
   "source": [
    "#import Image \n",
    "#import ImageOps\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning,SparseCoder\n",
    "from keras.datasets import mnist\n",
    "from function import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()\n",
    "\n",
    "iteration=500\n",
    "patch_hight=14\n",
    "patch_width=14\n",
    "num_basis=100\n",
    "\n",
    "#initialization of dictionary class\n",
    "t0=time()\n",
    "dict=MiniBatchDictionaryLearning(n_components=num_basis,alpha=1.0,transform_algorithm='lasso_lars',transform_alpha=1.0,fit_algorithm='lars',n_iter=iteration)\n",
    "\n",
    "M=np.mean(train_images,axis=0)[np.newaxis,:]\n",
    "white_image=train_images-M\n",
    "white_image/=np.std(white_image,axis=0)\n",
    "print(white_image)\n",
    "patches=np.empty((0,patch_hight,patch_width))\n",
    "\n",
    "for i in range(white_image[0].size):\n",
    "    patches_temp=extract_patch(train_images[i],patch_hight,patch_width)\n",
    "    patches=np.concatenate((patches,patches_temp),axis=0)\n",
    "\n",
    "patches=patches.reshape(patches.shape[0],-1)\n",
    "\n",
    "V=dict.fit(patches).components_\n",
    "np.save(\"dictionary.npy\",V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (100,196) and (28,28) not aligned: 196 (dim 1) != 28 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8c3bcde20b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msparsecoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSparseCoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform_n_nonzero_coefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msparsecoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/hikaruasano/.pyenv/versions/anaconda3-4.0.0/lib/python3.5/site-packages/sklearn/decomposition/dict_learning.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_algorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_n_nonzero_coefs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m             alpha=self.transform_alpha, n_jobs=self.n_jobs)\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_sign\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hikaruasano/.pyenv/versions/anaconda3-4.0.0/lib/python3.5/site-packages/sklearn/decomposition/dict_learning.py\u001b[0m in \u001b[0;36msparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, n_nonzero_coefs, alpha, copy_cov, init, max_iter, n_jobs, check_input, verbose)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcov\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'lasso_cd'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mcopy_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'lars'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'omp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (100,196) and (28,28) not aligned: 196 (dim 1) != 28 (dim 0)"
     ]
    }
   ],
   "source": [
    "sparsecoding=SparseCoder(V,transform_n_nonzero_coefs=30,transform_alpha=1.0)\n",
    "sparsecoding.transform(test_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-75004cfcf827>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-75004cfcf827>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    face=scipy.misc import face\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "face=scipy.misc import face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.feature_extraction.image import reconstruct_from_patches_2d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face=face(gray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distorting image...\n",
      "Extracting reference patches...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Height of the patch should be less than the height of the image.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-28f7847ca24b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mpatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_patches_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hikaruasano/.pyenv/versions/anaconda3-4.0.0/lib/python3.5/site-packages/sklearn/feature_extraction/image.py\u001b[0m in \u001b[0;36mextract_patches_2d\u001b[0;34m(image, patch_size, max_patches, random_state)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp_h\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mi_h\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         raise ValueError(\"Height of the patch should be less than the height\"\n\u001b[0m\u001b[1;32m    364\u001b[0m                          \" of the image.\")\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Height of the patch should be less than the height of the image."
     ]
    }
   ],
   "source": [
    "face=face/255.\n",
    "# downsample for higher speed\n",
    "face = face[::4, ::4] + face[1::4, ::4] + face[::4, 1::4] + face[1::4, 1::4]\n",
    "face /= 4.0\n",
    "height, width = face.shape\n",
    "\n",
    "# Distort the right half of the image\n",
    "print('Distorting image...')\n",
    "distorted = face.copy()\n",
    "distorted[:, width // 2:] += 0.075 * np.random.randn(height, width // 2)\n",
    "\n",
    "# Extract all reference patches from the left half of the image\n",
    "print('Extracting reference patches...')\n",
    "t0 = time()\n",
    "patch_size = (7, 7)\n",
    "data = extract_patches_2d(distorted[:, :width // 2], patch_size)\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "data -= np.mean(data, axis=0)\n",
    "data /= np.std(data, axis=0)\n",
    "print('done in %.2fs.' % (time() - t0))\n",
    "\n",
    "# #############################################################################\n",
    "# Learn the dictionary from reference patches\n",
    "\n",
    "print('Learning the dictionary...')\n",
    "t0 = time()\n",
    "dico = MiniBatchDictionaryLearning(n_components=100, alpha=1, n_iter=500)\n",
    "V = dico.fit(data).components_\n",
    "dt = time() - t0\n",
    "print('done in %.2fs.' % dt)\n",
    "\n",
    "plt.figure(figsize=(4.2, 4))\n",
    "for i, comp in enumerate(V[:100]):\n",
    "    plt.subplot(10, 10, i + 1)\n",
    "    plt.imshow(comp.reshape(patch_size), cmap=plt.cm.gray_r,\n",
    "               interpolation='nearest')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.suptitle('Dictionary learned from face patches\\n' +\n",
    "             'Train time %.1fs on %d patches' % (dt, len(data)),\n",
    "             fontsize=16)\n",
    "plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Display the distorted image\n",
    "\n",
    "def show_with_diff(image, reference, title):\n",
    "    \"\"\"Helper function to display denoising\"\"\"\n",
    "    plt.figure(figsize=(5, 3.3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Image')\n",
    "    plt.imshow(image, vmin=0, vmax=1, cmap=plt.cm.gray,\n",
    "               interpolation='nearest')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.subplot(1, 2, 2)\n",
    "    difference = image - reference\n",
    "\n",
    "    plt.title('Difference (norm: %.2f)' % np.sqrt(np.sum(difference ** 2)))\n",
    "    plt.imshow(difference, vmin=-0.5, vmax=0.5, cmap=plt.cm.PuOr,\n",
    "               interpolation='nearest')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.suptitle(title, size=16)\n",
    "    plt.subplots_adjust(0.02, 0.02, 0.98, 0.79, 0.02, 0.2)\n",
    "\n",
    "show_with_diff(distorted, face, 'Distorted image')\n",
    "\n",
    "# #############################################################################\n",
    "# Extract noisy patches and reconstruct them using the dictionary\n",
    "\n",
    "print('Extracting noisy patches... ')\n",
    "t0 = time()\n",
    "data = extract_patches_2d(distorted[:, width // 2:], patch_size)\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "intercept = np.mean(data, axis=0)\n",
    "data -= intercept\n",
    "print('done in %.2fs.' % (time() - t0))\n",
    "\n",
    "transform_algorithms = [\n",
    "    ('Orthogonal Matching Pursuit\\n1 atom', 'omp',\n",
    "     {'transform_n_nonzero_coefs': 1}),\n",
    "    ('Orthogonal Matching Pursuit\\n2 atoms', 'omp',\n",
    "     {'transform_n_nonzero_coefs': 2}),\n",
    "    ('Least-angle regression\\n5 atoms', 'lars',\n",
    "     {'transform_n_nonzero_coefs': 5}),\n",
    "    ('Thresholding\\n alpha=0.1', 'threshold', {'transform_alpha': .1})]\n",
    "\n",
    "reconstructions = {}\n",
    "for title, transform_algorithm, kwargs in transform_algorithms:\n",
    "    print(title + '...')\n",
    "    reconstructions[title] = face.copy()\n",
    "    t0 = time()\n",
    "    dico.set_params(transform_algorithm=transform_algorithm, **kwargs)\n",
    "    code = dico.transform(data)\n",
    "    patches = np.dot(code, V)\n",
    "\n",
    "    patches += intercept\n",
    "    patches = patches.reshape(len(data), *patch_size)\n",
    "    if transform_algorithm == 'threshold':\n",
    "        patches -= patches.min()\n",
    "        patches /= patches.max()\n",
    "    reconstructions[title][:, width // 2:] = reconstruct_from_patches_2d(\n",
    "        patches, (height, width // 2))\n",
    "    dt = time() - t0\n",
    "    print('done in %.2fs.' % dt)\n",
    "    show_with_diff(reconstructions[title], face,\n",
    "                   title + ' (time: %.1fs)' % dt)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distorting image...\n",
      "Extracting reference patches...\n",
      "done in 0.03s.\n",
      "Learning the dictionary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hikaruasano/.pyenv/versions/anaconda3-4.0.0/lib/python3.5/site-packages/sklearn/feature_extraction/image.py:287: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  indexing_strides = arr[slices].strides\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 3.10s.\n",
      "Extracting noisy patches... \n",
      "done in 0.00s.\n",
      "Orthogonal Matching Pursuit\n",
      "1 atom...\n",
      "done in 1.53s.\n",
      "Orthogonal Matching Pursuit\n",
      "2 atoms...\n",
      "done in 3.22s.\n",
      "Least-angle regression\n",
      "5 atoms...\n",
      "done in 17.17s.\n",
      "Thresholding\n",
      " alpha=0.1...\n",
      "done in 0.16s.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.feature_extraction.image import reconstruct_from_patches_2d\n",
    "\n",
    "\n",
    "try:  # SciPy >= 0.16 have face in misc\n",
    "    from scipy.misc import face\n",
    "    face = face(gray=True)\n",
    "except ImportError:\n",
    "    face = sp.face(gray=True)\n",
    "\n",
    "# Convert from uint8 representation with values between 0 and 255 to\n",
    "# a floating point representation with values between 0 and 1.\n",
    "face = face / 255.\n",
    "\n",
    "# downsample for higher speed\n",
    "face = face[::4, ::4] + face[1::4, ::4] + face[::4, 1::4] + face[1::4, 1::4]\n",
    "face /= 4.0\n",
    "height, width = face.shape\n",
    "\n",
    "# Distort the right half of the image\n",
    "print('Distorting image...')\n",
    "distorted = face.copy()\n",
    "distorted[:, width // 2:] += 0.075 * np.random.randn(height, width // 2)\n",
    "\n",
    "# Extract all reference patches from the left half of the image\n",
    "print('Extracting reference patches...')\n",
    "t0 = time()\n",
    "patch_size = (7, 7)\n",
    "data = extract_patches_2d(distorted[:, :width // 2], patch_size)\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "data -= np.mean(data, axis=0)\n",
    "data /= np.std(data, axis=0)\n",
    "print('done in %.2fs.' % (time() - t0))\n",
    "\n",
    "# #############################################################################\n",
    "# Learn the dictionary from reference patches\n",
    "\n",
    "print('Learning the dictionary...')\n",
    "t0 = time()\n",
    "dico = MiniBatchDictionaryLearning(n_components=100, alpha=1, n_iter=500)\n",
    "V = dico.fit(data).components_\n",
    "dt = time() - t0\n",
    "print('done in %.2fs.' % dt)\n",
    "\n",
    "plt.figure(figsize=(4.2, 4))\n",
    "for i, comp in enumerate(V[:100]):\n",
    "    plt.subplot(10, 10, i + 1)\n",
    "    plt.imshow(comp.reshape(patch_size), cmap=plt.cm.gray_r,\n",
    "               interpolation='nearest')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.suptitle('Dictionary learned from face patches\\n' +\n",
    "             'Train time %.1fs on %d patches' % (dt, len(data)),\n",
    "             fontsize=16)\n",
    "plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Display the distorted image\n",
    "\n",
    "def show_with_diff(image, reference, title):\n",
    "    \"\"\"Helper function to display denoising\"\"\"\n",
    "    plt.figure(figsize=(5, 3.3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Image')\n",
    "    plt.imshow(image, vmin=0, vmax=1, cmap=plt.cm.gray,\n",
    "               interpolation='nearest')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.subplot(1, 2, 2)\n",
    "    difference = image - reference\n",
    "\n",
    "    plt.title('Difference (norm: %.2f)' % np.sqrt(np.sum(difference ** 2)))\n",
    "    plt.imshow(difference, vmin=-0.5, vmax=0.5, cmap=plt.cm.PuOr,\n",
    "               interpolation='nearest')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.suptitle(title, size=16)\n",
    "    plt.subplots_adjust(0.02, 0.02, 0.98, 0.79, 0.02, 0.2)\n",
    "\n",
    "show_with_diff(distorted, face, 'Distorted image')\n",
    "\n",
    "# #############################################################################\n",
    "# Extract noisy patches and reconstruct them using the dictionary\n",
    "\n",
    "print('Extracting noisy patches... ')\n",
    "t0 = time()\n",
    "data = extract_patches_2d(distorted[:, width // 2:], patch_size)\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "intercept = np.mean(data, axis=0)\n",
    "data -= intercept\n",
    "print('done in %.2fs.' % (time() - t0))\n",
    "\n",
    "transform_algorithms = [\n",
    "    ('Orthogonal Matching Pursuit\\n1 atom', 'omp',\n",
    "     {'transform_n_nonzero_coefs': 1}),\n",
    "    ('Orthogonal Matching Pursuit\\n2 atoms', 'omp',\n",
    "     {'transform_n_nonzero_coefs': 2}),\n",
    "    ('Least-angle regression\\n5 atoms', 'lars',\n",
    "     {'transform_n_nonzero_coefs': 5}),\n",
    "    ('Thresholding\\n alpha=0.1', 'threshold', {'transform_alpha': .1})]\n",
    "\n",
    "reconstructions = {}\n",
    "for title, transform_algorithm, kwargs in transform_algorithms:\n",
    "    print(title + '...')\n",
    "    reconstructions[title] = face.copy()\n",
    "    t0 = time()\n",
    "    dico.set_params(transform_algorithm=transform_algorithm, **kwargs)\n",
    "    code = dico.transform(data)\n",
    "    patches = np.dot(code, V)\n",
    "\n",
    "    patches += intercept\n",
    "    patches = patches.reshape(len(data), *patch_size)\n",
    "    if transform_algorithm == 'threshold':\n",
    "        patches -= patches.min()\n",
    "        patches /= patches.max()\n",
    "    reconstructions[title][:, width // 2:] = reconstruct_from_patches_2d(\n",
    "        patches, (height, width // 2))\n",
    "    dt = time() - t0\n",
    "    print('done in %.2fs.' % dt)\n",
    "    show_with_diff(reconstructions[title], face,\n",
    "                   title + ' (time: %.1fs)' % dt)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
